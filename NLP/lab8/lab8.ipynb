{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лабораторна робота №8, Обробка та аналіз текстових даних на Python, Варіант 14\n",
    "**Виконав**: студент групи ІП-11, Лошак Віктор Іванович<br>\n",
    "**Перевірив**: Юлія Тимофєєва Сергіївна<br>\n",
    "\n",
    "**Тема роботи**: Синтаксичні залежності у spaCy<br>\n",
    "**Мета роботи**: Ознайомитись з використанням класу Matcher. Ознайомитись із синтаксичними залежностями та їх застосуванням для виявлення намірів\n",
    "\n",
    "25.05.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Завдання**:<br>\n",
    "1.  Використати  клас  Matcher для  виділення  сутностей. Виділити пункти відправлення за допомогою класу Matcher. Виділити висловлювання користувача, де він просить щось змінити (наприклад, Find me something else.), за допомогою шаблонів. Використати файл з 7-ї лабораторної роботи (не обов’язково усі висловлювання). Продемонструвати роботу.  \n",
    "2.  Застосувати  синтаксичні  залежності для  визначення  намірів. Використати  файл  з  7-ї  лабораторної  роботи  (не  обов’язково  усі \n",
    "висловлювання).\n",
    "\n",
    "**Task**:<br>\n",
    "1. Use the Matcher class to select entities. Select departure points using the Matcher class. Highlight user statements where they ask for something to be changed (for example, Find me something else.) using templates. Use the file from the 7th laboratory work (not necessarily all statements). Demonstrate work.  \n",
    "2. Apply syntactic dependencies to determine intentions. Use the file from the 7th laboratory work (not necessarily all \n",
    "statement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import json\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I want to find a one way flight.',\n",
       " 'I am flying to Phoenix, AZ. I want 1 ticket from Seattle, WA.',\n",
       " \"I want to depart 11th of March. I don't care which airline.\",\n",
       " 'A different airline please, in Premium Economy.',\n",
       " 'Find me something else. I want to fly with Southwest Airlines. Look for them from Atlanta.',\n",
       " 'Alright.',\n",
       " 'No thanks for your help.',\n",
       " 'I would like to find a one way flight. I am interested in flights from Vegas.',\n",
       " 'I will be heading to Toronto, Canada. I would like to start my travel on the 13th of March.',\n",
       " 'What is the airport the flight will be landing at?']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"flights.json\") as file:\n",
    "    data = json.load(file)\n",
    "    querries = []\n",
    "    for dialogue in data:\n",
    "        for turn in dialogue[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                querries.append(turn[\"utterance\"])\n",
    "\n",
    "querries[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(' '.join(querries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from Seattle',\n",
       " 'from Atlanta',\n",
       " 'from Vegas',\n",
       " 'from Los',\n",
       " 'from Phoenix',\n",
       " 'from SD',\n",
       " 'from NYC',\n",
       " 'from Las',\n",
       " 'from Chi',\n",
       " 'from Philadelphia']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": {\"IN\": [\"from\", \"departing\"]}}, {\"IS_ALPHA\": True, \"IS_STOP\": False, \"LENGTH\": {\">=\": 2}}]\n",
    "matcher.add(\"DEPARTURE_CITY\", [pattern])\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "results = []\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    # print(span.text)\n",
    "    results.append(span.text)\n",
    "    \n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched string: A different airline please, in Premium Economy.\n",
      "Matched string: Find me something else. I want to fly with Southwest Airlines. Look for them from Atlanta.\n",
      "Matched string: Find me something else with United Airlines.\n",
      "Matched string: Find me something else.\n",
      "Matched string: Find me something else.\n",
      "Matched string: Try to find me something different. I would like 1 ticket with Southwest Airlines.\n",
      "Matched string: Try to find me something different. I would like 1 ticket with Southwest Airlines.\n",
      "Matched string: Can you find me something else?\n",
      "Matched string: This Saturday please. Oh, actually, change that to 3 tickets.\n",
      "Matched string: Can you find something else. I'm just wondering if there is something that will work out better for us.\n",
      "Matched string: Find me something else, Delta Airlines instead, economy tickets.\n",
      "Matched string: I would like to continue trying to make the reservation, let's try a flight to SF. My plans may change, so I only want to find refundable tickets.\n",
      "Matched string: I need to book two tickets. My plans might change, so I need refundable tickets only. My departure location is Vancouver, BC. We'll be departing this Sunday, on our way to Phoenix, USA.\n",
      "Matched string: Actually, can you change the flight date to the 3rd?\n"
     ]
    }
   ],
   "source": [
    "# Define a pattern for change requests\n",
    "matcher = Matcher(nlp.vocab)\n",
    "change_patterns = [\n",
    "    [{\"LEMMA\": \"find\"}, {\"POS\": \"PRON\", \"OP\": \"?\"}, {\"LEMMA\": \"something\", \"OP\": \"?\"}, {\"LOWER\": {\"IN\": [ \"different\", \"other\", \"alternative\", \"else\"]}}],\n",
    "    [{\"LEMMA\": \"change\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}],\n",
    "    [{\"LEMMA\": \"alter\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}],\n",
    "    [ {\"LEMMA\": \"different\"}],\n",
    "    \n",
    "]\n",
    "matcher.add(\"CHANGE_REQUEST\", change_patterns)\n",
    "\n",
    "with open(\"flights.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    for dialogue in data:\n",
    "        for turn in dialogue['turns']:\n",
    "            if turn['speaker'] == 'USER':\n",
    "                doc = nlp(turn['utterance'])\n",
    "                matches = matcher(doc)\n",
    "                for match_id, start, end in matches:\n",
    "                    span = doc[start:end]\n",
    "                    # print(f\"Matched Change Request: {span.text}\")\n",
    "                    print(f\"Matched string: {turn['utterance']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I want to find a one way flight.\n",
      "Intentions: ['find flight']\n",
      "Sentence: I am flying to Phoenix, AZ. I want 1 ticket from Seattle, WA.\n",
      "Intentions: ['want ticket']\n",
      "Sentence: I want to depart 11th of March. I don't care which airline.\n",
      "Intentions: ['depart 11th', 'care airline']\n",
      "Sentence: Find me something else. I want to fly with Southwest Airlines. Look for them from Atlanta.\n",
      "Intentions: ['Find something']\n",
      "Sentence: I would like to find a one way flight. I am interested in flights from Vegas.\n",
      "Intentions: ['find flight']\n",
      "Sentence: I will be heading to Toronto, Canada. I would like to start my travel on the 13th of March.\n",
      "Intentions: ['start travel']\n",
      "Sentence: What time does the flight get there?\n",
      "Intentions: ['get time']\n",
      "Sentence: No. I appreciate your help.\n",
      "Intentions: ['appreciate help']\n",
      "Sentence: I need to find a one way flight.\n",
      "Intentions: ['find flight']\n",
      "Sentence: I will need flights from Los Angeles. Can you find me something with Alaska Airlines?\n",
      "Intentions: ['need flights', 'find something']\n",
      "Sentence: Okay thank you anyways, that is all I need.\n",
      "Intentions: ['thank you']\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "with open('flights.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    for dialogue in data:\n",
    "        for turn in dialogue['turns']:\n",
    "            if turn['speaker'] == 'USER':\n",
    "                doc = nlp(turn['utterance'])\n",
    "                # print(F\"Sentence:\", doc.text)\n",
    "                # print(\"Intentions:\")\n",
    "                intentions = []\n",
    "                for token in doc:\n",
    "                    if token.dep_ == \"dobj\":  # Check for direct objects in the sentence\n",
    "                        dobj = token.text  # Text of the direct object\n",
    "                        # conj = [t.text for t in token.conjuncts]  # List any conjunctions related to the direct object\n",
    "                        # The verb (action) associated with the direct object\n",
    "                        verb = token.head\n",
    "                        # print(verb, dobj)\n",
    "                        intentions.append(verb.text+' '+ dobj)\n",
    "\n",
    "                if intentions:\n",
    "                    results[doc.text] = intentions\n",
    "\n",
    "for i, key in enumerate(results.keys()):\n",
    "    if i> 10:\n",
    "        break\n",
    "    print(F\"Sentence:\", key)\n",
    "    print(\"Intentions:\", results[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Висновок:\n",
    "В ході виконання даної лабораторної роботи я ознайомився з методами синтаксичного аналізу текстів за допомогою бібліотеки spaCy, зокрема з класами Matcher та PhraseMatcher для виділення сутностей та визначення намірів користувачів. Завдання полягало у використанні цих класів для виявлення місць відправлення та висловлювань з проханням змін у діалогах з файлу \"flights.json\".\n",
    "\n",
    "Мною було створено шаблони для виділення пунктів відправлення, що дозволяло виявляти локації у реченнях користувачів, які запитували про авіарейси. Також я розробив шаблони для ідентифікації фраз, де користувачі просять про зміну чи вибір іншого варіанту, що важливо для систем автоматизованого обслуговування клієнтів.\n",
    "\n",
    "Окрім того, я застосував синтаксичні залежності для аналізу залежностей у реченнях, що дало змогу глибше зрозуміти структуру висловлювань та визначати наміри користувачів більш точно. Це дозволило визначати наміри користувачів не тільки за ключовими словами, а й за структурою речень."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
